{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Markov Chain </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This project contains an overview of Markov chains and their implementation in finance specifically in credit risk modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first start by mathematically detailing the different characteristics of the Markov chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Markov chain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b> Notation </b> : We note $(X_n)_{n\\geq0} \\in E^{\\mathbb{N}}$ a sequence of random variables indexed to $\\mathbb{N}$  with values in a set $E$. It will be more commonly noted $(X_n)$ or $X$.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><b>Definition 1.1 [Markov Chain]</b> A sequence of random varaibles $(X_n)_{n\\geq0}$ with values in a countable state space (finite or infinite) $E$ is a Markov chain if for every $n ≥ 0$ and every $x_0,...,x_{n+1} \\in E$ we have : $$\\mathbb{P}(X_{n+1} = x_{n+1} | X_n = x_n,...,X_0 = x_0) = P(X_{n+1} = x_{n+1} | X_n = x_n)$$\n",
    "\n",
    "If, on the other hand $\\mathbb{P}(X_{n+1} =x_{n+1} |X_n =x_n) = \\mathbb{P}(X_1 =x_{n+1} |X_0 = x_n)$, we say that $(X_n)$ is <i>homogeneous in time </i>. </div>\n",
    "\n",
    "In other words, a sequence of random variables $(X_n)$ with values in a countable state space $E$ is therefore a Markov chain if conditionally to present, future and past are independent. A trivial example of a Markov chain is the case where the $X_i$ are independent and identically distributed (i.i.d.). \n",
    "\n",
    "Throughout the notebook, in accordance with our application cases, we will consider Markov chain in a countable state space (finite or infinite) and <b>homogeneous in time.\n",
    "\n",
    "For a time-homogeneous Markov chain, the probability $\\mathbb{P}(X_{n+1} = y | X_n = x)$  does not depend on time (ie $n$): we call this probability **transition probability** (from $x$ to $y$) and we note it $$p_{xy} =P(X_{n+1} = y| X_n = x)=P(X_1 = y| X_0 = x)$$\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Definition 1.2 [Transition matrix] </b> The set of transition probabilities defines the transition matrix denoted $P$ and defined by: $$P=(p_{xy})_{x,y \\in E}$$</div>\n",
    "\n",
    "If $E$ is infinite, then $P$ is an \"infinite matrix\".  \n",
    "$P$ is a stochastic matrix, i.e. it verifies the following properties: \n",
    "\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}{rl}\n",
    "        \\forall x,y \\in E, & p_{xy} \\geq 0 \\\\\n",
    "        \\forall x \\in E, & \\sum_{y\\in E} p_{xy} = 1\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Both conditions allow us to assert that $\\forall x,y \\in E,  p_{xy} \\in [0,1]$. So these are probabilities. In addition, the second condition tells us that for each line, the sum of its elements is $1$. This means that starting from a state $ x \\in E $ at the moment $n$, we will go into a state of $E$ at the moment $n+1$ almost surely ($\\mathbb{P}(X_1 \\in E | X_0 = x) = 1$ for any $x \\in E$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us give some classic examples of Markov chains homogeneous in time and over a countable state space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Example 1** : Markov chain with 2 states in $E = \\{0,1\\}$.\n",
    "<img src=\"Images/Markov.png\" width=\"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have: $p_{0,1} = p_{1,0} = 1 - p_{0,0} = 1 - p_{1,1} = p \\in [0,1]$, and so the transition matrix is given by $P = \\begin{pmatrix} 1-p & p \\\\ p & 1-p \\end{pmatrix}$ which is well stochastic.\n",
    "In other words, we change states with a probability $p$ and we stay in the same state with a probability $1-p$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Example 2** : Random walk with $E = \\mathbb{N}$ : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/MarkovN.png\" width=\"600px\"></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have: $p_{x,x+1} = 1 - p_{x,x-1} = p$ for $x>0$ and $p_{0,1} = 1 - p_{0,0} = p$, and therefore the transition matrix is given by the infinite \"matrix\"  $P = \\begin{pmatrix} 1-p & p & 0 & 0 & ...\\\\ \n",
    "                                    1-p & 0 & p & 0 & ...\\\\\n",
    "                                    0 & 1-p & 0 & p & ...\\\\\n",
    "                                    0 & 0 & 1-p & 0 & ...\\\\\n",
    "                                    ... & ... & ...& ... & ...\\end{pmatrix}$ \n",
    "                                    \n",
    "Which is stochastic. In other words, in all cases, we go to the right with a probability $p $. On the other hand, if we are in $x>0$, we go to the left with a probability $1-p$ and if we are in $x=0$, we stay in $0$ with a probability $1-p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Example 2** : Weather prediction : Markov chain with 3 states : \n",
    "\n",
    "<img src=\"Images/FilRouge.png\" width=\"600px\"></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the Markov chain represented by this state graph. For $\\ngeq0$, we put $X_n$ the weather on the day $n$, so that the weather on the day $n$ depends only on the weather on the day $n-1$. $(X_n)$ is therefore a Markov chain and it can take 3 values: *sunshine* (state $0$), *rain* (state $1$) and *snow* (state $2$).  \n",
    "The transition matrix is given by $P = \\begin{pmatrix} 0.5 & 0.3 & 0.2\\\\ \n",
    "                                    0.45 & 0.45 & 0.1 \\\\\n",
    "                                    0.4 & 0.3 & 0.3 \\end{pmatrix}$ \n",
    "is a stochastic matrix.\n",
    "\n",
    "For example, if it rains on Monday, there is a 45% chance that the weather will be nice on Tuesday and a 10% chance that it will snow on Tuesday.\n",
    "\n",
    "In the rest of this notebook, we will use numpy arrays to manipulate the different matrices and vectors. Indexing requires the use of integers and not states such as \"sunshine\" for example.\n",
    "\n",
    "\n",
    "We're going to associate an integer with each state $x \\in E$ : <i>sunshine : 0</i>, <i>rain : 1</i> et <i>snow : 2</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f02710\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\"sunshine\" : 0, \"rain\" : 1, \"snow\" : 2}\n",
    "inv_stats = dict((n,k) for k, n in stats.items())\n",
    "liste_states = list(stats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix :\n",
      "           sunshine  rain  snow\n",
      "sunshine      0.50  0.30   0.2\n",
      "rain          0.45  0.45   0.1\n",
      "snow          0.40  0.30   0.3\n"
     ]
    }
   ],
   "source": [
    "#transition matrix \n",
    "transition_matrix = pd.DataFrame([[.5,.3,.2],[.45,.45,.1],[.4,.3,.3]],\n",
    "                                 columns=liste_states, index=liste_states)\n",
    "print(\"Transition matrix :\\n\", transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All matrix's elements are postive -- :>  True\n",
      "Sum of all probabilities per row is egal to 1 -- :>  True\n",
      "P is stochastic -- :>  True\n"
     ]
    }
   ],
   "source": [
    "# Check if the transition matrix is stochastic \n",
    "# postivity \n",
    "print(\"All matrix's elements are postive -- :> \", np.sum(np.sum(transition_matrix>= 0)) == len(liste_states)**2)\n",
    "\n",
    "print(\"Sum of all probabilities per row is egal to 1 -- :> \", np.sum(np.sum(transition_matrix, axis = 1)) == len(liste_states))\n",
    "\n",
    "print(\"P is stochastic -- :> \", (np.sum(np.sum(transition_matrix>= 0)) == len(liste_states)**2) & \n",
    "      (np.sum(np.sum(transition_matrix, axis = 1)) == len(liste_states)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_chain(nmax, P):\n",
    "    \"\"\"\n",
    "    This function returns weather predictions based on Markov chain\n",
    "    input : \n",
    "        - nmax : number of predictions for each simulation\n",
    "        - P: transition matrix \n",
    "    \"\"\"\n",
    "    list_stat_temp = list(np.zeros(nmax))\n",
    "    for i in range(1, len(list_stat_temp)) :\n",
    "        list_stat_temp[i] = np.random.choice([0,1,2],\n",
    "                                             size=1,\n",
    "                                             p=list(P.iloc[int(list_stat_temp[i-1])].tolist()))[0]\n",
    "        \n",
    "\n",
    "    output_states = [inv_stats[ele] for ele in list_stat_temp]\n",
    "    return output_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of weather predictions using Markov chaine : \n",
      " \n",
      "1 : ['sunshine', 'snow', 'rain', 'sunshine', 'rain', 'rain', 'rain']\n",
      "2 : ['sunshine', 'sunshine', 'sunshine', 'sunshine', 'sunshine', 'sunshine', 'sunshine']\n",
      "3 : ['sunshine', 'rain', 'rain', 'rain', 'rain', 'rain', 'rain']\n",
      "4 : ['sunshine', 'rain', 'rain', 'sunshine', 'sunshine', 'rain', 'sunshine']\n",
      "5 : ['sunshine', 'sunshine', 'sunshine', 'sunshine', 'sunshine', 'sunshine', 'rain']\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of weather predictions using Markov chaine : \\n \")\n",
    "for i in range(5):\n",
    "    predicted_states = markov_chain(7, transition_matrix)\n",
    "    print(\"{} : {}\".format(i+1,predicted_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><b>Definition 1.3  </b> The distribution of a sequence of random variables $(X_n)_{\\ngeq0}$ is the probability of $\\mathbb{P}(X_0 = x_0,...,X_n = x_n)$ for any $n \\geq 0$ and any $x_0,...,x_n \\in E$.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b> Notation </b> : To simplify from now on, for any $\\ngeq0$ we note $X_0^n = (X_k)_{k \\in [0,n]}$  the \"chain killed\" at the moment $n$ and $x_0^n = (x_k)_{k \\in [ 0,n]} $ a sequence of states between the moments $0$ and $n$.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Theorem 1.1 </b> : If $X$ is a transition matrix Markov chain $P$, then for all $\\ngeq0$ and $x_0^n \\in E^{n+1}$, we have: $$\\mathbb{P}(X_0^n = x_0^n) = \\mathbb{P}(X_0 = x_0)\\prod_{i=1}^n p_{x_{i−1}x_i}.$$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To compute the Markov chain distribution, we therefore need initial conditions $\\mathbb{P}(X_0 = 0)$, $\\mathbb{P}(X_0 = 1)$ and $\\mathbb{P}(X_0 = 2)$. For the moment, in our example we don't know them. We will therefore assume that we start from $0$ such that $\\mathbb{P}(X_0 = 0) = 1$, and we will calculate the probability of some realization $x_0,...,x_n \\in E$ with the formula above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X_0-3 = ['sunshine', 'sunshine', 'rain', 'snow']) = 0.015\n"
     ]
    }
   ],
   "source": [
    "n = 3 # number of observations \n",
    "obeservations = np.random.randint(0,3,n+1)\n",
    "obeservations[0] = 0 #we assume that we start from 0 with a probability egal to 1\n",
    "observation_stats = [inv_stats[obs] for obs in obeservations]\n",
    "proba = 1\n",
    "for i in range(1,n+1):\n",
    "    proba *= transition_matrix.iloc[obeservations[i-1],obeservations[i]]\n",
    "print(\"P(X_0-{} = {}) = {}\" .format(n, observation_stats,proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to know the distribution of X, we need to the transition matrix as well as the inital probability $\\mathbb{P}(X_0 = x_0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the notebook, we note $\\pi_0$ the initial probability with $\\pi_0 = (\\pi_0(x))_{x \\in E}$ and $\\pi_0(x) = \\mathbb{P}(X_0 = x)$.\n",
    "\n",
    "We note as well, $\\pi_n$ the distribution of $X_n$,  i.e. $\\pi_n = (\\pi_n(x))_{x \\in E}$ with $\\pi_n(x) = \\mathbb{P}(X_n = x)$.\n",
    "\n",
    "For every $n\\geq0$, $\\pi_n$ is a column vector of $[0,1]^{E}$ that contains probabilities $\\mathbb{P}(X_n = x)$ for every $x\\in E$.\n",
    "\n",
    "<div class=\"alert alert-warning\"><b>Theorem  1.2 </b> :  The sequence of variables $(\\pi_n)_{n \\geq 0}$ verifies the following deterministic linear dynamical system: $$\\forall n \\geq 0, \\ \\pi^T_{n+1} = \\pi^T_n P$$\n",
    "In particular, $\\forall n \\geq 0, \\ \\pi_n^T = \\pi_0^T P^n$.</div>\n",
    "\n",
    "The $(X_n)$ law is then fully defined by $P$ and $\\pi_0$. We can therefore denote a time-homogeneous Markov chain by the couple $(pi_0,P)$.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of X_n for n in [0,10] : \n",
      "\n",
      "P(X1 = sunshine) = 0.445000, P(X1 = rain) = 0.375000, P(X1 = snow) = 0.180000\n",
      "P(X2 = sunshine) = 0.463250, P(X2 = rain) = 0.356250, P(X2 = snow) = 0.180500\n",
      "P(X3 = sunshine) = 0.464137, P(X3 = rain) = 0.353437, P(X3 = snow) = 0.182425\n",
      "P(X4 = sunshine) = 0.464086, P(X4 = rain) = 0.353016, P(X4 = snow) = 0.182899\n",
      "P(X5 = sunshine) = 0.464059, P(X5 = rain) = 0.352952, P(X5 = snow) = 0.182988\n",
      "P(X6 = sunshine) = 0.464054, P(X6 = rain) = 0.352943, P(X6 = snow) = 0.183004\n",
      "P(X7 = sunshine) = 0.464052, P(X7 = rain) = 0.352941, P(X7 = snow) = 0.183006\n",
      "P(X8 = sunshine) = 0.464052, P(X8 = rain) = 0.352941, P(X8 = snow) = 0.183006\n",
      "P(X9 = sunshine) = 0.464052, P(X9 = rain) = 0.352941, P(X9 = snow) = 0.183007\n",
      "P(X10 = sunshine) = 0.464052, P(X10 = rain) = 0.352941, P(X10 = snow) = 0.183007\n"
     ]
    }
   ],
   "source": [
    "#Initial probabilities \n",
    "pi_0 = np.array([.2, .5, .3])\n",
    "\n",
    "#Computations of pi_n\n",
    "N = 10\n",
    "pi = pi_0\n",
    "print(\"Distribution of X_n for n in [0,{}] : \\n\".format(N))\n",
    "for n in range(N):\n",
    "    pi = pi@transition_matrix\n",
    "    print(\"P(X%d = sunshine) = %f, P(X%d = rain) = %f, P(X%d = snow) = %f\" % (n+1,pi[0],n+1,pi[1],n+1,pi[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id=\"sec2\"></a> Markov model's hidden theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will give the main definitions of hidden Markov model theory as well as its main properties. We will illustrate them using the weather prediction example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the interest of the theory of hidden Markov models, let's complete our example common thread. We always have our Markov string $(X_n)$ with values in a state space $E = \\{sunshine,rain,snow\\}$ and transition matrix given by $P = \\begin{pmatrix} 0.5 & 0.3 & 0.2\\\\ \n",
    "                                    0.45 & 0.45 & 0.1 \\\\\n",
    "                                    0.4 & 0.3 & 0.3 \\end{pmatrix}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose that we are in a room without windows and without thermal insulation, so that we can not see the weather, but we can know if it is hot or cold outside. Weather is therefore hidden from us, unknown, but every day we have access to an observation, the temperature, allowing us to have an idea about the weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(X_n)$ becomes a **hidden sequence** and every day the temperature is an **observation**. We assume that the observation made on the day $n$ depends only on the weather on that day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we have the following probabilities : \n",
    "* $\\mathbb{P}(cold|sunshine) = 0.3$ and $\\mathbb{P}(hot|sunshine) = 0.7$ \n",
    "* $\\mathbb{P}(cold|rain) = 0.8$ and $\\mathbb{P}(hot|rain) = 0.2$ \n",
    "* $\\mathbb{P}(cold|snow) = 1$ and $\\mathbb{P}(hot|snow) = 0$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our state graph thus becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/HiddenFilRouge.png\" width=\"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if it rains monday, there is an 80% chance that it will be cold on monday and 20% that it will be hot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just converted our weather prediction Markov chain into a **hidden Markov model**, with a hidden sequence that we don't have access to (weather) and a sequence of observations (temperature) that we have access to. Let's formalize this idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Definitions\n",
    "\n",
    "The hidden Markov model generalizes the observable Markov model because it produces a sequence using two sequences of random variables: one hidden and the other observable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><b>Definition 2.1 [Hidden Markov chain] A hidden Markov</b> model is the data of two sequences of random variables: \n",
    "<li>The hidden sequence, $(X_n)_{n\\geq0}$, which is a \"classical\" Markov chain homogeneous in time and values in a countable state space $E$. </li>\n",
    "<li>The sequence of observations, $(O_n)_{n\\geq0}$, which is a sequence of random and valued variables in a countable set $\\mathcal{V}$ called <i>vocabulary</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all $\\ngeq0$, these two suites check the relationship: $$\\forall v_0,...,v_n \\in \\mathcal{V}, \\forall x_0,...,x_n \\in E, , \\mathbb{P}(O_n = v_n | X_0^n = x_0^n, O_0^{n-1} = v_0^{n-1}) = \\mathbb{P}(O_n = v_n | X_n = x_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, on the other hand, $\\forall n\\geq0, \\forall v \\in \\mathcal{V}, \\forall x \\in E, \\mathbb{P}(O_n = v | X_n = x) = \\mathbb{P}(O_0 = v | X_0 = x)$, The model is said to be <i>stationary</i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, for a stationary hidden Markov model, for $x\\in E$ and $v \\in \\mathcal{V}$, the probability $\\mathbb{P}(O_n = v | X_n = x)$ does not depend on time: we call this probability **probability of emission** (from $x$ to $v$) and we note it $$b_{xv} = \\mathbb{P}(O_n = v|X_n = x) = \\mathbb{P}(O_0 = v|X_0 = x)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on and in accordance with our application cases, we will consider Markov models hidden in a finite state space $E$ (of cardinal $N \\geq1$), <b>homogeneous in time</b>, with a <b>finite vocabulary</b> (of cardinal $|\\mathcal{V}|$) and <b>stationary</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><b>Definition 2.2 [Emission matrix]</b> The set of emission probabilities defines the emission matrix denoted $B$ and defined by: $$B=(b_{xv})_{x \\in E, v \\in \\mathcal{V}}$$ </div>\n",
    "In the same way as the transition matrix of the Markov chain, the emission matrix is a stochastic matrix, i.e. it verifies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left\\{\n",
    "    \\begin{array}{rl}\n",
    "        \\forall x \\in E, \\forall v \\in \\mathcal{V}, & b_{xv} \\geq 0 \\\\\n",
    "        \\forall x \\in E, & \\sum_{v\\in \\mathcal{V}} b_{xv} = 1\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Convention </b> For the same reason as for states, we will associate an integer with each element of the vocabulary for indexing the emission matrix: <i>cold: 0</i> and <i>hot: 1</i>.\n",
    "\n",
    "Let's implement the emission matrix of our hidden Markov chain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définition du vocabulaire\n",
    "vocabulary = {'Cold':0, 'Hot':1}\n",
    "inv_vocabulary = dict((n,k) for k, n in vocabulary.items())\n",
    "list_vocabulary = list(vocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Matrice d'émission :\n",
      "          Cold  Hot\n",
      "sunshine  0.3  0.7\n",
      "rain      0.8  0.2\n",
      "snow        1    0\n"
     ]
    }
   ],
   "source": [
    "#Définition de la matrice d'émission\n",
    "b_df = pd.DataFrame(columns=list_vocabulary, index=stats)\n",
    "b_df.loc[list(stats.keys())[0]] = [.3,.7]\n",
    "b_df.loc[list(stats.keys())[1]] = [0.8,0.2]\n",
    "b_df.loc[list(stats.keys())[2]] = [1,0]\n",
    "B = b_df.values.astype(\"float\")\n",
    "print(\"\\n Matrice d'émission :\\n\",b_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a sequence of observations from a hidden Markov model, the following procedure must be followed: \n",
    "* 1 - Pick randomly the initial state $X_0$ according to the initial distribution $pi_0$\n",
    "* 2 - Pick randomly the initial observation $O_0$ according to the emission probabilities corresponding to $X_0$\n",
    "\n",
    "* 3 - From the state $X_i$ at the moment $i$, go to the following state $X_{i+1}$ according to the transition probabilities.\n",
    "* 4 - pick randomly the observation $O_{i+1}$ at the moment $i+1$ according to the emission probabilities\n",
    "* 5 - Go back to step 3 and start again until the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_markov_model(n,pi_0,P,B): \n",
    "    \"\"\"\n",
    "    Generation of a sequence of (n+1) stats and (n+1) observations between two times 0 and n.\n",
    "    \n",
    "    Inputs : \n",
    "        n : lenght of sequence \n",
    "        pi_0 : initial distribution of hidden sequence\n",
    "        P : transition matrix\n",
    "        B : emission matrix \n",
    "    \"\"\"\n",
    "\n",
    "    X_n = np.zeros(n+1,dtype=int)\n",
    "    O_n = np.zeros(n+1,dtype=int)\n",
    "    E = list(range(P.shape[0])) #States\n",
    "    V = list(range(B.shape[1])) #Vocabulary\n",
    "    \n",
    "    #initialisation\n",
    "    X_n[0] = np.random.choice(E,size=1,p=pi_0)\n",
    "    O_n[0] = np.random.choice(V,size=1,p = list(B[X_n[0]]))\n",
    "    \n",
    "    #recurrence \n",
    "    for i in range(n):\n",
    "        X_n[i+1] = np.random.choice(E,size=1,p = list(P.iloc[X_n[i]]))\n",
    "        O_n[i+1] = np.random.choice(V,size=1,p = list(B[X_n[i+1]]))\n",
    "    return X_n,O_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of sequences generated  with a hidden Markov Chain : \n",
      "\n",
      "X_0 = rain, O_0 = Cold\n",
      "X_1 = sunshine, O_1 = Cold\n",
      "X_2 = sunshine, O_2 = Cold\n",
      "X_3 = sunshine, O_3 = Hot\n",
      "X_4 = rain, O_4 = Hot\n",
      "X_5 = sunshine, O_5 = Hot\n"
     ]
    }
   ],
   "source": [
    "X,O = hidden_markov_model(5,pi_0,transition_matrix,B)\n",
    "print(\"Examples of sequences generated  with a hidden Markov Chain : \\n\")\n",
    "for i in range(len(X)):\n",
    "    print(\"X_\" + str(i) + \" = \" + inv_stats[X[i]] +\", O_\" + str(i) + \" = \"+ inv_vocabulary[O[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Law of Process $(X,O)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as for classical Markov chains, let's look at the law of the sequence $(X_n,O_n)_{\\ngeq0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b>Theorem 2.1 </b> : For any $n \\geq 0$, all $x_0, ..., x_n \\in E$ and for any $v_0, ..., v_n \\in \\mathcal{V}$, we have:\n",
    "$$\\mathbb{P}(X_0^n = x_0^n, O_0^n = v_0^n) = pi_0(x_0)\\prod_{i=0}^n b_{x_iv_i} \\prod_{i=1}^n p_{x_{i-1}x_i}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof of theorem 2.1: Let $x_0, ..., x_n \\in E$ and $v_0, ..., v_n \\in \\mathcal{V}$. We have: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}(X_0^n = x_0^n, O_0^n = v_0^n) &= \\mathbb{P}(O_0^n = v_0^n | X_0^n = x_0^n) \\mathbb{P}(X_0^n = x_0^n) \\\\\n",
    "&= \\mathbb{P}(X_0^n = x_0^n) \\mathbb{P}(O_0 = v_0 | X_0^n = x_0^n) \\prod_{i=1}^n \\mathbb{P}(O_i = v_i | X_0^n = x_0^n, O_0^{i-1} = v_0^{i-1})\\\\\n",
    "&= \\mathbb{P}(X_0^n = x_0^n) \\prod_{i=0}^n \\mathbb{P}(O_i = v_i | X_i = x_i) \\ \\ \\ \\text{by the Markov property on the observations} \\\\\n",
    "&= \\pi_0(x_0)\\prod_{i=0}^n b_{x_iv_i} \\prod_{i=1}^n p_{x_{i-1}x_i} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This theorem allows us to assert that the law of the process $(X,O)$ is therefore entirely determined by $pi_0$, $P$ and $B$. In the same way as for classical Markov chains, one can denote a hidden Makov chain by the triplet $(pi_0,P,B)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "realisations = np.random.randint(0,3,n+1)\n",
    "sequence_obs = np.random.randint(0,2,n+1)\n",
    "realisation_stats = [inv_stats[n] for n in realisations]\n",
    "observations_stats = [inv_vocabulary[n] for n in sequence_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X_0^2 = ['rain', 'rain', 'rain'],O_0^2 = ['Cold', 'Cold', 'Hot']) = 0.012960000000000003\n"
     ]
    }
   ],
   "source": [
    "#Calcul de la probabilité d'une réalisation de (X,O)\n",
    "proba = pi_0[realisations[0]] * B[realisations[0],sequence_obs[0]]\n",
    "for i in range(1,n+1):\n",
    "    proba *= transition_matrix.iloc[realisations[i-1],realisations[i]] * B[realisations[i],sequence_obs[i]]\n",
    "print(\"P(X_0^{} = {},O_0^{} = {}) = {}\".format(n, realisation_stats,n,observations_stats,proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id=\"sec3\"></a> The three fundamental problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a data scientist decides to use a hidden Markov model to represent a phenomenon, for example in natural language processing, a big problem arises: the sequence of states is not accessible, he only has the sequence of obervations. Two types of situations are then possible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Either the parameters $(pi_0,P,B)$ are known and we can then make calculations under this model\n",
    "* Or they are not, in which case we would like to determine them from observations, as a neural network would."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b> Notation </b> : In this whole part, for a hidden Markov model $\\lambda = (pi_0,P,B)$ and a sequence of observations $v_0^n \\in \\mathcal{V}^{n+1}$, we note by $\\mathbb{P}_\\lambda(O_0^n = v_0^n)$ the probability that the hidden model $\\lambda$ emitted the sequence $v_0^n$.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Convention </b> : In line with the integer/<i>state and integer/</i><i>word</i> correspondences we have created, the algorithms in this part will only process integers (in other words: $E = [\\![ 0,N-1]\\!] $ and $\\mathcal{V} = [\\![ 0,|\\mathcal{V}| - 1]\\!] $) Conversion to states and words will be done through correspondence dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence of obervations $v_0^n \\in \\mathcal{V}^{n+1}$, there are three fundamental problems that deserve our attention and need to be solved:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Problem 1 (probability calculation)**: given a model $\\lambda = (pi_0,P,B)$, efficiently calculate the probability of observing this sequence\n",
    "* **Problem 2 (decryption)**: given a $\\lambda = (pi_0,P,B)$ pattern, determine the most likely corresponding sequence of states $x_0^n \\in E^{n+1}$\n",
    "* **Problem 3 (training)**: determine the parameters of the model $\\lambda^* = (pi_0^*,P^*,B^*)$ that maximize $\\mathbb{P}_{\\lambda}(O_0^n = v_0^n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id=\"sec2\"></a> Application of Markov Chain in Finance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Market Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerning market trend. These are tree types : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bull markets: periods of time where prices generally are rising, due to the actors having optimistic hopes of the future.\n",
    "- Bear markets: periods of time where prices generally are declining, due to the actors having a pessimistic view of the future.\n",
    "- Stagnant markets : periods of time where the market is characterized by neither a decline nor rise in general prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have the following transition probabilities :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Market_Trend.JPG\" width=\"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a week characterized of a bull market trend there is a 90% chance that another bullish week will follow. Additionally, there is a 7.5% chance that the bull week instead will be followed by a bearish one, or a 2.5% chance that it will be a stagnant one. After a bearish week there’s an 80% chance that the upcoming week also will be bearish, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's consider the following transition matrix\n",
    "transition_matrix = np.array([[0.9,0.075,0.025],\n",
    "              [0.15,0.8,0.05], \n",
    "              [0.25,0.25,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that we strat from a stagnant state\n",
    "state=np.array([[0.0,0.0,1.0]]) \n",
    "\n",
    "# Initialize our list in which we store the states at each iteration\n",
    "state_historic = state \n",
    "\n",
    "# Convert it to dataframe\n",
    "df_state_historic = pd.DataFrame(state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we choose 100 iterations \n",
    "for x in range(100): \n",
    "    \n",
    "    # we multiply liste of states with matrix trnasition \n",
    "    state=np.dot(state,transition_matrix) \n",
    "    \n",
    "    # add the new prediction to state_historic list\n",
    "    state_historic=np.append(state_historic,state,axis=0) \n",
    "    \n",
    "    # convert state_historic to dataframe\n",
    "    df_state_historic = pd.DataFrame(state_historic)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c49d2b75e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting graph\n",
    "plt.figure(figsize=(10,5)) \n",
    "sns.lineplot(data=df_state_historic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to Markov Chain, after 100 iterations (weeks in our case) : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is 62.5% chance that market will be bullish\n",
    "- There is 31.25% chance that market will be bearish\n",
    "- There is 62.5% chance that market will be stagnant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationnary distribution of Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, the distribution becomes stationnary after 18 iterations. How we can explain that ?\n",
    "\n",
    "As seen previously : \n",
    "    \n",
    "$$\\forall n \\geq 0, \\ \\pi^T_{n+1} = P \\pi^T_n $$ \n",
    "   \n",
    "In particular, $\\forall n \\geq 0, \\ \\pi_n^T = P^n \\pi_0^T $.</div>\n",
    "\n",
    "P is a transition matrix: each element is a transition probability from a state to another : $\\forall x,y \\in E,  p_{xy} \\in [0,1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><b> Perron Frobenius' theorem  </b> :\n",
    "\n",
    "Let A be a N by N irreducible matrix with positive coefficients : \n",
    "    \n",
    "- There is a positive real number r, called the Perron root or the Perron–Frobenius eigenvalue (also called the leading eigenvalue or dominant eigenvalue), such that r is an eigenvalue of A and any other eigenvalue λ (possibly complex) in absolute value is strictly smaller than r , |λ| < r. Thus, the spectral radius $\\rho$ (A) is equal to r.\n",
    "- If s and S are respectively the maximum and minimum sums of each row, so : $ s \\leq \\rho (A) \\leq S  $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the sum of each row of P is equal to 1 (each row contains the transition probabilities from a state to others) So : \n",
    "                $$ 1 \\leq \\rho \\; (P) \\leq 1  \\Leftrightarrow \\rho \\; (P) = 1 $$\n",
    "                \n",
    "And any other eignevalue is smaller than 1: |λ| < 1\n",
    "\n",
    "P is diagonalizable because it's symmetric, so we can write P = $ V \\; diag(\\lambda) \\; V^T $\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "   \\forall n \\geq 0, \\ \\pi_n^T &= P^n \\pi_0^T    \\\\\n",
    "    &=(V \\; diag(\\lambda) \\; V^T)^n \\; \\pi_0^T  \\\\  \n",
    "    &=(V \\; diag(\\lambda)^n \\; V^T) \\; \\pi_0^T  \\\\\n",
    "\\end{align}\n",
    "\n",
    "This process forces all non-zero eigenvalues smaller than 1 to decrease until zero. \n",
    "\n",
    "After a certain number of iterations, diag($\\lambda$) will have one eigenvalue equal to 1 and the ohers to zero. Thus,  $$\\forall n \\geq 0, \\ \\pi_n^T = P' \\pi_0^T$$\n",
    "\n",
    "Which converges to a stationnary distribution, called also equilibrium distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
